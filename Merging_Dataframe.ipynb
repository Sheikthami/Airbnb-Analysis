{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOB1bYOMIH3WhBTaT/XIbyT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z28bcLUW556t",
        "outputId": "30c3adfe-ce0d-478c-fa83-c6b283c0f382"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=26795605ba517bdde61a5a9ae712358fa4d36f180f0d1edaeff92fe241291b21\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "LhxNpi1R5vC3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark = SparkSession.Builder().appName('merging').getOrCreate()"
      ],
      "metadata": {
        "id": "HJaCox4q60NG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df = spark.read.load('/content/sales_data_set.csv',format = 'csv',header = True,inferSchema = True)\n",
        "stores_df = spark.read.load('/content/stores_data_set.csv',format = 'csv',header = True,inferSchema = True)\n",
        "features_df = spark.read.load('/content/Features_data_set.csv',format = 'csv',header = True,inferSchema = True)\n",
        "\n",
        "print('Number of rows : ',sales_df.count()), display(sales_df)\n",
        "print('Number of rows : ',stores_df.count()), display(stores_df)\n",
        "print('Number of rows : ',features_df.count()), display(features_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "ORsJp1e_65pJ",
        "outputId": "3576b65b-0027-43ce-b700-be02e9065a55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows :  421570\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[Store: int, Dept: int, Date: string, Weekly_Sales: double, IsHoliday: boolean]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows :  45\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[Store: int, Type: string, Size: int]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows :  8190\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[Store: int, Date: string, Temperature: double, Fuel_Price: double, MarkDown1: string, MarkDown2: string, MarkDown3: string, MarkDown4: string, MarkDown5: string, CPI: string, Unemployment: string, IsHoliday: boolean]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merge_df = sales_df.join(stores_df, on = 'Store', how = 'inner')\n",
        "print('Number of rows : ',merge_df.count()), display(merge_df)\n",
        "\n",
        "merge_df1 = merge_df.join(features_df, on = ['Store','Date','IsHoliday'], how = 'inner')\n",
        "print('Number of rows : ',merge_df1.count()), display(merge_df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "56RcvSzV71_D",
        "outputId": "8e04615f-a98b-4ded-e7ba-a736bbcf4f1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows :  421570\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[Store: int, Dept: int, Date: string, Weekly_Sales: double, IsHoliday: boolean, Type: string, Size: int]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows :  421570\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[Store: int, Date: string, IsHoliday: boolean, Dept: int, Weekly_Sales: double, Type: string, Size: int, Temperature: double, Fuel_Price: double, MarkDown1: string, MarkDown2: string, MarkDown3: string, MarkDown4: string, MarkDown5: string, CPI: string, Unemployment: string]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xvOigsz45ihV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge_df1.createOrReplaceTempView('merge_df')"
      ],
      "metadata": {
        "id": "MkcukhT58YgW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_df = spark.sql('''select year(Date) as Year, Store, `Type` as Store_Type ,Dept, Temperature, Fuel_Price, CPI, Unemployment,\n",
        "                        sum(Weekly_Sales) as Total_Sales from merge_df\n",
        "                        group by Year, Store, Store_Type, Dept, Temperature, Fuel_Price, CPI, Unemployment''')\n",
        "\n",
        "print('Number of rows : ',query_df.count()), display(query_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "OIy-hWaP8bt5",
        "outputId": "c6ab444c-00a5-4150-d793-99494e271185"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows :  421570\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[Year: int, Store: int, Store_Type: string, Dept: int, Temperature: double, Fuel_Price: double, CPI: string, Unemployment: string, Total_Sales: double]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write CSV file with column header (column names)\n",
        "query_df.write.option(\"header\",True).csv(\"/FileStore/tables/consolidate/merged_df\")"
      ],
      "metadata": {
        "id": "buyd-Jhx8f4O"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}